{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7d1e472",
   "metadata": {},
   "source": [
    "\n",
    "FashionMNIST 是一个用于图像分类的常用数据集，旨在作为 MNIST 手写数字数据集的直接替代品。它由 Zalando Research 创建，解决了 MNIST 数据集对于现代机器学习任务而言过于简单的问题。\n",
    "\n",
    "## 数据特性\n",
    "\n",
    "* **类别：** 数据集包含 10 种不同的时尚产品类别，例如 **T 恤/上衣**、**裤子**、**套头衫**、**连衣裙**、**外套**、**凉鞋**、**衬衫**、**运动鞋**、**包**和**踝靴**。\n",
    "* **图像：** 每张图像都是**单通道**（灰度）的**黑白图像**，尺寸为 **28x28 像素**。这意味着每个像素的值范围为 0 到 255，表示其灰度强度。\n",
    "* **数据集划分：**\n",
    "    * **训练集：** 包含 **60,000 张图像**，用于模型训练。\n",
    "    * **测试集：** 包含 **10,000 张图像**，用于评估训练后模型的性能。\n",
    "* **样本示例：** 您提供的图片展示了 FashionMNIST 数据集中的一些样本示例，每个小图对应一个样本，清晰地展示了不同类别的时尚物品。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062d36d0",
   "metadata": {},
   "source": [
    "# 1.导入包\n",
    "* torch 是 PyTorch 的主库，它提供了强大的张量（Tensor）计算功能，所有的神经网络操作都基于这些多维数组。它也包含了自动求导系统，这是反向传播和模型训练的核心机制。\n",
    "\n",
    "* torch.nn (neural network) 模块是 PyTorch 中构建神经网络层的“工具箱”。从最基本的全连接层（Linear）到卷积层（Conv2d）、循环神经网络层（RNN）以及各种激活函数和损失函数，你都能在这里找到。它极大地简化了神经网络架构的搭建。\n",
    "\n",
    "* torch.optim (optimizer) 模块则提供了各种优化算法。当你计算出模型的错误（损失）后，这些优化器会根据梯度来调整模型的内部参数（权重），让模型在每一次迭代中都变得更好。常见的优化器有 SGD、Adam 等。\n",
    "\n",
    "* torch.utils.data.DataLoader 和 torchvision.datasets、torchvision.transforms 是一套高效处理数据的组合。datasets 提供了许多现成的数据集（比如 MNIST、ImageNet），而 transforms 则能让你对图像进行各种预处理（如缩放、裁剪、归一化）。DataLoader 能帮你以批次（batch）的形式高效地加载和迭代数据，这对于训练大型模型至关重要，因为它能大大提高数据吞吐量。\n",
    "\n",
    "* matplotlib.pyplot 和 numpy 是 Python 数据科学领域常用的辅助工具。matplotlib.pyplot 是一个强大的绘图库，能帮你可视化训练过程中的损失曲线、准确率变化，或者展示图像数据等，是理解模型行为的得力助手。numpy 则是进行科学计算的基础库，虽然 PyTorch 有自己的张量操作，但 numpy 在数据预处理和后处理中仍然非常有用，两者可以方便地进行数据转换。\n",
    "\n",
    "* tqdm.auto 能为你的循环迭代添加一个美观且实用的进度条。在训练深度学习模型时，一个 epoch 可能需要很长时间，tqdm 能让你清晰地看到训练的实时进度，避免“假死”的焦虑，极大地提升了开发体验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10cb6211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Duplicate key in file PosixPath('/usr/local/lib/python3.9/dist-packages/matplotlib/mpl-data/matplotlibrc'), line 799 ('font.family: sans-serif')\n",
      "Duplicate key in file PosixPath('/usr/local/lib/python3.9/dist-packages/matplotlib/mpl-data/matplotlibrc'), line 800 ('font.sans-serif: SimHei')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm # 推荐用于显示训练进度\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "272b8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用“device”，后续对要使用GPU的变量用.to(device)即可\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#此外还可以使用os.environ\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689dc9b3",
   "metadata": {},
   "source": [
    "# 2.配置超参数\n",
    "\n",
    "#### 1. 动态学习率调整\n",
    "\n",
    "我启用了学习率调度器，将其降低因子设为 0.5。这意味着当模型在验证集上的性能连续3个Epoch未见显著提升时，学习率会自动减半。我认为这种基于性能反馈的动态调整，比固定学习率更能帮助模型稳定且深入地找到最优解。\n",
    "\n",
    "#### 2. 精准的早停机制\n",
    "\n",
    "同时，我实施了精准的早停策略，设定当模型在验证集上连续7个Epoch的性能提升低于0.0001时，训练将立即终止。这是为了有效防止模型过拟合，并在模型泛化能力达到最佳时及时停止，避免浪费计算资源。\n",
    "\n",
    "#### 3. `batch_size` 的调整考量\n",
    "\n",
    "在实验中，我审慎地降低了batch_size。虽然小批量可能引入更多梯度噪声，但我认为这有助于模型探索更丰富的梯度方向，从而潜在地提升模型的泛化能力，并降低对GPU显存的需求，增加了实验的灵活性。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfefb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置其他超参数，如batch_size, num_workers, learning rate, 以及总的epochs\n",
    "batch_size = 64\n",
    "num_workers = 0  \n",
    "# num_workers: 根据操作系统和并行需求配置\n",
    "# 对于 Windows 系统，通常必须设置为 0\n",
    "# 对于 Linux/macOS，如果希望并行加载数据，可以设置为 CPU 核心数的一半或更少\n",
    "lr = 1e-4\n",
    "epochs = 20 #训练轮数\n",
    "\n",
    "\n",
    "# 早停参数\n",
    "patience = 7     # 在验证集性能连续多少个epoch没有提升时停止\n",
    "min_delta = 0.0001 # 性能提升的最小阈值，小于这个值不算提升\n",
    "\n",
    "# 学习率调度器参数\n",
    "lr_factor = 0.5  # 学习率每次降低的因子\n",
    "lr_patience = 3  # 在验证集性能连续多少个epoch没有提升时降低学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "809821c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子，确保结果可以复现\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed452b",
   "metadata": {},
   "source": [
    "# 数据集处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee98717",
   "metadata": {},
   "source": [
    "这里使用了数据增强，具体如下：\n",
    "原始图像数组 → ToPILImage() → Resize(28) → 随机水平翻转 → 随机旋转 → 填充+随机裁剪 → ToTensor() → 标准化 → 输出张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c958a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(28),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomCrop(28, padding=4),  # 替代RandomResizedCrop更适合小尺寸图像\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST标准化参数\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8268586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 二、自定义数据集优化（使用真实数据加载逻辑）\n",
    "# # 注意：以下代码假设你有真实数据集路径，若使用随机数据仅用于测试\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, data_dir, transform=None):\n",
    "#         # 真实场景应从文件加载数据\n",
    "#         # 示例：使用imageio读取图像\n",
    "#         self.images = []\n",
    "#         self.targets = []\n",
    "#         # 这里应替换为实际数据加载逻辑\n",
    "#         # for img_path, label in data_loader:\n",
    "#         #     self.images.append(imageio.imread(img_path))\n",
    "#         #     self.targets.append(label)\n",
    "        \n",
    "#         # 临时使用随机数据模拟（仅测试用）\n",
    "#         self.images = np.random.randint(0, 255, (5000, 28, 28, 1), dtype=np.uint8)\n",
    "#         self.targets = np.random.randint(0, 10, 5000, dtype=np.int64)\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __getitem__(self, item):\n",
    "#         image = self.images[item]\n",
    "#         label = self.targets[item]\n",
    "        \n",
    "#         # 处理单通道图像（添加维度）\n",
    "#         if len(image.shape) == 2:\n",
    "#             image = image[:, :, np.newaxis]\n",
    "            \n",
    "#         if self.transform:\n",
    "#             # 区分处理torchvision和imgaug变换\n",
    "#             if isinstance(self.transform, transforms.Compose):\n",
    "#                 image = self.transform(image)\n",
    "#             else:\n",
    "#                 image = self.transform(image)\n",
    "                \n",
    "#         return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0009d0",
   "metadata": {},
   "source": [
    "这段代码自定义了 PyTorch 数据集类FMDataset，用于加载 FashionMNIST 数据。它从 CSV 文件解析图像像素和标签，支持自定义变换（如归一化、增强）。实例化时，分别读取训练集和测试集 CSV，应用数据变换后生成可迭代的数据集对象，供模型训练和评估使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba86abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.images = df.iloc[:,1:].values.astype(np.uint8)\n",
    "        self.labels = df.iloc[:, 0].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape(28,28,1)\n",
    "        label = int(self.labels[idx])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.tensor(image/255., dtype=torch.float)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "train_df = pd.read_csv(\"/home/jovyan/work/datasets/6645b9bbc4db0a94029f0bfe-momodel/FashionMNIST/fashion-mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"/home/jovyan/work/datasets/6645b9bbc4db0a94029f0bfe-momodel/FashionMNIST/fashion-mnist_test.csv\")\n",
    "train_data = FMDataset(train_df, data_transform)\n",
    "test_data = FMDataset(test_df, data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "603e45f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "515500ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efcd06d5d30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(train_loader))\n",
    "print(image.shape, label.shape)\n",
    "plt.imshow(image[0][0], cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2d301",
   "metadata": {},
   "source": [
    "### 模型架构优化策略\n",
    "我对模型进行了三方面优化：\n",
    "* 一是将原始 5x5 无填充卷积核改为 3x3 且 padding=1 的卷积核，这样多个 3x3 卷积核堆叠可获与大卷积核相近感受野，参数量更少且能引入更多非线性激活，同时 padding=1 可保留特征图空间尺寸避免边缘信息流失；\n",
    "* 二是在每个卷积层后、ReLU 前加入 BatchNorm2d 层，以规范化各层输入分布，缓解 “内部协变量偏移”，稳定训练、加速收敛并起正则化作用；\n",
    "* 三是将 Dropout 层从卷积层后调整至全连接层之间，因卷积层后用 Dropout 可能破坏特征图空间相关性，而全连接层更易过拟合，在此处用 Dropout 能削弱神经元共适应性，提升模型泛化能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5221343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class OptimizedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OptimizedNet, self).__init__()\n",
    "        # 第一个卷积块（调整顺序：Conv → BatchNorm → ReLU → Pooling）\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 第二个卷积块\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 全连接层（适当调整神经元数量）\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)  # 增加到512，增强表达能力\n",
    "        self.dropout1 = nn.Dropout(0.4)  # 减小Dropout比例\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "        self.fc3 = nn.Linear(256, 10)  # 输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 第一个卷积块\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)  # ReLU移到Pooling前\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # 第二个卷积块\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)  # ReLU移到Pooling前\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # 展平\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "\n",
    "        # 全连接层（增加一层，增强非线性表达）\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c7d1268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedNet(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=3136, out_features=512, bias=True)\n",
      "  (dropout1): Dropout(p=0.4, inplace=False)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (dropout2): Dropout(p=0.4, inplace=False)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = OptimizedNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3da5e",
   "metadata": {},
   "source": [
    "# 损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "488e6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.CrossEntropyLoss(weight=[1,1,1,1,3,1,1,1,1,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504bfac8",
   "metadata": {},
   "source": [
    "### 加权交叉熵损失函数（Weighted Cross Entropy Loss）公式解释\n",
    "\n",
    "交叉熵损失函数（Cross Entropy Loss）是多分类任务中最常用的损失函数，它衡量的是模型预测的概率分布与真实标签的概率分布之间的差异。当引入“权重”时，其核心思想是：**对不同类别的预测错误，给予不同的“惩罚”力度**。对于那些你希望模型更关注、更重视的类别（例如数据量稀少的少数类别），可以赋予更高的权重。\n",
    "\n",
    "让我们定义以下符号：\n",
    "\n",
    "* $N$：批处理（Batch）中的样本总数。\n",
    "* $C$：总的类别数量。\n",
    "* $y_i$：第 $i$ 个样本的真实类别标签（一个整数，从 $0$ 到 $C-1$）。\n",
    "* $z_{ij}$：模型为第 $i$ 个样本预测的属于第 $j$ 个类别的原始分数（也称为 Logits）。\n",
    "* $w_j$：为第 $j$ 个类别分配的权重。默认情况下，所有 $w_j$ 都为 $1$。\n",
    "\n",
    "PyTorch 的 `nn.CrossEntropyLoss` 内部会自动执行 Softmax 运算，然后计算负对数似然损失。\n",
    "\n",
    "**1. Softmax 概率计算：**\n",
    "首先，模型输出的原始分数 $z_{ij}$ 会通过 Softmax 函数转换为概率 $p_{ij}$。对于第 $i$ 个样本，其属于第 $j$ 个类别的预测概率为：\n",
    "$$p_{ij} = \\frac{e^{z_{ij}}}{\\sum_{k=0}^{C-1} e^{z_{ik}}}$$\n",
    "其中，$e^{z_{ij}}$ 是以 $e$ 为底 $z_{ij}$ 的指数，分母是所有类别指数的和，确保所有类别的概率之和为 1。\n",
    "\n",
    "**2. 单个样本的加权负对数似然损失：**\n",
    "对于第 $i$ 个样本，其真实的类别是 $y_i$。在加权交叉熵损失中，我们只关注模型对真实类别的预测概率，并将其乘以对应类别的权重。\n",
    "单个样本的加权损失 $L_i^{weighted}$ 可以表示为：\n",
    "$$L_i^{weighted} = -w_{y_i} \\cdot \\log(p_{i, y_i})$$\n",
    "这里的 $w_{y_i}$ 是第 $y_i$ 个真实类别所对应的权重，$\\log(p_{i, y_i})$ 是模型对真实类别 $y_i$ 预测概率的自然对数。负号是因为我们希望最大化对数似然，等价于最小化负对数似然。\n",
    "\n",
    "**3. 批处理的最终损失：**\n",
    "整个批处理的最终损失通常是对所有样本的加权损失取平均值（当 `reduction='mean'` 时，这是 PyTorch 的默认行为）：\n",
    "$$L_{总} = \\frac{1}{N} \\sum_{i=1}^{N} L_i^{weighted}$$\n",
    "将 $L_i^{weighted}$ 的表达式代入，得到 PyTorch 中加权交叉熵损失的完整计算公式：\n",
    "$$L_{总} = -\\frac{1}{N} \\sum_{i=1}^{N} w_{y_i} \\cdot \\log \\left( \\frac{e^{z_{i, y_i}}}{\\sum_{k=0}^{C-1} e^{z_{ik}}} \\right)$$\n",
    "\n",
    "这个公式的核心在于 $w_{y_i}$ 这个权重因子。当某个真实类别 $y_i$ 被赋予更高的权重时，模型对该类别预测错误的损失值就会相应地被放大。这使得优化器在反向传播时，会更“努力”地调整参数以减少这些高权重类别的预测误差，从而在类别不平衡的数据集中提升模型对少数类别的识别能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15276144",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87398aeb",
   "metadata": {},
   "source": [
    "设定优化器【待补充】"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aefb961",
   "metadata": {},
   "source": [
    "* 前向传播：model(data)通过模型计算预测输出。\n",
    "* 损失计算：criterion（通常是交叉熵或均方误差）计算预测值与真实标签的差异。\n",
    "* 反向传播：loss.backward()计算梯度，将误差反向传播到各参数。\n",
    "* 参数更新：optimizer.step()根据优化器（如 Adam/SGD）更新模型权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75065cbb",
   "metadata": {},
   "source": [
    "# 训练与验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0208e512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data, label in train_loader:\n",
    "#         data, label = data.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6306687a",
   "metadata": {},
   "source": [
    "封装成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c62d9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证\n",
    "def val(epoch):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    gt_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "#             data, label = data.cuda(), label.cuda()\n",
    "            output = model(data)\n",
    "            preds = torch.argmax(output, 1)#最大值\n",
    "            gt_labels.append(label.cpu().data.numpy())#搜集真实标签\n",
    "            pred_labels.append(preds.cpu().data.numpy())#收集预测标签\n",
    "            loss = criterion(output, label)\n",
    "            val_loss += loss.item()*data.size(0)\n",
    "    val_loss = val_loss/len(test_loader.dataset)\n",
    "    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)\n",
    "    acc = np.sum(gt_labels==pred_labels)/len(pred_labels)\n",
    "    print('Epoch: {} \\tValidation Loss: {:.6f}, Accuracy: {:6f}'.format(epoch, val_loss, acc))\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594a431",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bd7391f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.788272\n",
      "Epoch: 1 \tValidation Loss: 0.583177, Accuracy: 0.773700\n",
      "Epoch 1 | Current LR: 0.001000\n",
      "Epoch: 2 \tTraining Loss: 0.605809\n",
      "Epoch: 2 \tValidation Loss: 0.467676, Accuracy: 0.819700\n",
      "Epoch 2 | Current LR: 0.001000\n",
      "Epoch: 3 \tTraining Loss: 0.540884\n",
      "Epoch: 3 \tValidation Loss: 0.439723, Accuracy: 0.832700\n",
      "Epoch 3 | Current LR: 0.001000\n",
      "Epoch: 4 \tTraining Loss: 0.493096\n",
      "Epoch: 4 \tValidation Loss: 0.417763, Accuracy: 0.843600\n",
      "Epoch 4 | Current LR: 0.001000\n",
      "Epoch: 5 \tTraining Loss: 0.463096\n",
      "Epoch: 5 \tValidation Loss: 0.376449, Accuracy: 0.860100\n",
      "Epoch 5 | Current LR: 0.001000\n",
      "Epoch: 6 \tTraining Loss: 0.438218\n",
      "Epoch: 6 \tValidation Loss: 0.377978, Accuracy: 0.860200\n",
      "Epoch 6 | Current LR: 0.001000\n",
      "Epoch: 7 \tTraining Loss: 0.416688\n",
      "Epoch: 7 \tValidation Loss: 0.339020, Accuracy: 0.872100\n",
      "Epoch 7 | Current LR: 0.001000\n",
      "Epoch: 8 \tTraining Loss: 0.400248\n",
      "Epoch: 8 \tValidation Loss: 0.343333, Accuracy: 0.871900\n",
      "Epoch 8 | Current LR: 0.001000\n",
      "Epoch: 9 \tTraining Loss: 0.391833\n",
      "Epoch: 9 \tValidation Loss: 0.339017, Accuracy: 0.872700\n",
      "Epoch 9 | Current LR: 0.001000\n",
      "Epoch: 10 \tTraining Loss: 0.381613\n",
      "Epoch: 10 \tValidation Loss: 0.326890, Accuracy: 0.878500\n",
      "Epoch 10 | Current LR: 0.001000\n",
      "Epoch: 11 \tTraining Loss: 0.373048\n",
      "Epoch: 11 \tValidation Loss: 0.312428, Accuracy: 0.882900\n",
      "Epoch 11 | Current LR: 0.001000\n",
      "Epoch: 12 \tTraining Loss: 0.365462\n",
      "Epoch: 12 \tValidation Loss: 0.319704, Accuracy: 0.877200\n",
      "Epoch 12 | Current LR: 0.001000\n",
      "Epoch: 13 \tTraining Loss: 0.361442\n",
      "Epoch: 13 \tValidation Loss: 0.315286, Accuracy: 0.880300\n",
      "Epoch 13 | Current LR: 0.001000\n",
      "Epoch: 14 \tTraining Loss: 0.352888\n",
      "Epoch: 14 \tValidation Loss: 0.354924, Accuracy: 0.863600\n",
      "Epoch 14 | Current LR: 0.001000\n",
      "Epoch: 15 \tTraining Loss: 0.348953\n",
      "Epoch: 15 \tValidation Loss: 0.297558, Accuracy: 0.888600\n",
      "Epoch 15 | Current LR: 0.001000\n",
      "Epoch: 16 \tTraining Loss: 0.343857\n",
      "Epoch: 16 \tValidation Loss: 0.289225, Accuracy: 0.890200\n",
      "Epoch 16 | Current LR: 0.001000\n",
      "Epoch: 17 \tTraining Loss: 0.342780\n",
      "Epoch: 17 \tValidation Loss: 0.291899, Accuracy: 0.887200\n",
      "Epoch 17 | Current LR: 0.001000\n",
      "Epoch: 18 \tTraining Loss: 0.337425\n",
      "Epoch: 18 \tValidation Loss: 0.282688, Accuracy: 0.897300\n",
      "Epoch 18 | Current LR: 0.001000\n",
      "Epoch: 19 \tTraining Loss: 0.331744\n",
      "Epoch: 19 \tValidation Loss: 0.283710, Accuracy: 0.894000\n",
      "Epoch 19 | Current LR: 0.001000\n",
      "Epoch: 20 \tTraining Loss: 0.328196\n",
      "Epoch: 20 \tValidation Loss: 0.273075, Accuracy: 0.899500\n",
      "Epoch 20 | Current LR: 0.001000\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler  # 导入学习率调度器模块\n",
    "\n",
    "# 假设已有模型和优化器\n",
    "model = OptimizedNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 初始化调度器\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch)\n",
    "    val_loss = val(epoch)  # 假设val函数返回验证集损失\n",
    "    \n",
    "    # 更新学习率\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # 打印当前学习率\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch} | Current LR: {current_lr:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2085c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/jovyan/work/results/FahionModel.pkl\"\n",
    "torch.save(model, save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
